_target_: lipreading.models.lrs2_sentence_module.LRS2SentenceModule

optimizer:
  _target_: lipreading.optimizer.build_optimizer
  _partial_: true
  config:
    name: AdamW
    lr: 0.0003

scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  _partial_: true
  T_max: "${trainer.max_epochs}"
  eta_min: 0.000001

model:
  _target_: lipreading.models.components.pytorch_transformer.Backend
  _partial_: true
  d_model: 512
  num_heads: 8
  num_encoder_layers: 6
  num_decoder_layers: 6
  p_dropout: 0.1

loss:
  type: CrossEntropyLoss

warmup:
  name: linear
  steps: 5000 # 因为bs很小，必须上升足够的step
  ratio: 0.01

load_model: null