# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /data: lrs2.yaml
  - override /model: resnet_transformer.yaml
  - override /callbacks: default.yaml
  - override /trainer: gpu.yaml
  - override /logger: tensorboard.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["lrs2", "resnet","transformer"]

seed: 12345

trainer:
  max_epochs: 80
  gradient_clip_val: 35
  check_val_every_n_epoch: 5
  accumulate_grad_batches: 10
  precision: 16

data:
  batch_size: 4
  num_workers: 16
  pretrain: True

callbacks:
  early_stopping:
    monitor: val/wer
    mode: min
    patience: 20

  model_checkpoint:
    filename: epoch_{epoch:03d}_val-wer_{val/wer:03f}
    monitor: val/wer
    mode: min

paths:
  log_dir: ${paths.root_dir}/logs/resnet_transformer

logger:
  tensorboard:
    name: resnet_transformer
    
